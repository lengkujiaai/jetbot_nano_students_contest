{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循迹\n",
    "\n",
    "如果您已经完成了避免碰撞示例，那么您应该熟悉以下三个步骤\n",
    "\n",
    "1. 数据采集\n",
    "2. 训练\n",
    "3. 部署方式\n",
    "\n",
    "在此notebook中，我们将做同样的事情！除了分类之外，您将学习另一种基本技术，**回归**，我们将用它使JetBot遵循一条道路（或实际上是任何路径或目标点）。\n",
    "\n",
    "将JetBot放置在路径上的不同位置（与中心的偏移，不同角度等）\n",
    "请记住，从避免碰撞的角度来看，数据变化是关键！\n",
    "\n",
    "显示来自机器人的实时视频\n",
    "使用游戏手柄控制器，在图像上放置一个“绿点”，该绿点对应于我们希望机器人移动的目标方向。\n",
    "将绿点的X，Y值以及机器人相机的图像存在一起。\n",
    "然后，在训练notebook中，我们将训练神经网络来预测标签的X，Y值。在现场演示中，我们将使用预测的X，Y值来计算近似的转向值（这不是“精确”的角度，因为这需要进行图像校准，但它与角度大致成比例，因此我们的控制器可以正常工作）。\n",
    "\n",
    "那么，如何确定本示例中目标的确切位置？我们认为可能会有所帮助的指导\n",
    "\n",
    "1. 看一下摄像机的实时视频\n",
    "2. 想象一下机器人应该遵循的路径（尝试估算出可以避免偏离路径所需的距离）。\n",
    "3. 将目标沿着此路径尽可能远地放置，以使机器人可以直奔目标而不会“偏离”道路。\n",
    "> 例如，如果我们处在非常直的道路上，则可以将其放置在地平线上。如果我们位于急转弯处，则可能需要将其放置在离机器人更近的位置，以免超出边界。\n",
    "\n",
    "假设我们的深度学习模型按预期工作，则这些标签准则应确保以下各项：\n",
    "\n",
    "1. 机器人可以安全地直接朝目标行进（不会越界等）\n",
    "2. 目标将沿着我们想象的道路不断前进\n",
    "我们得到的是沿着我们期望的轨迹移动，深度学习决定把目标放在哪里，jetbot会紧随其后:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标记示的例视频\n",
    "执行代码块以查看如何标记图像的示例。该模型仅需123张图像即可工作，可根据实际效果来增加采集量:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/display.py:701: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.bilibili.com/video/BV17f4y127pn/\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.bilibili.com/video/BV17f4y127pn/\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入python库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们开始导入用于“数据收集”目的的所有必需库。我们将主要使用OpenCV来可视化并保存带有标签的图像。uuid，datetime之类的库用于图像命名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython Libraries for display and widgets\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Camera and Motor Interface for JetBot\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "# Python basic pakcages for image annotation\n",
    "from uuid import uuid1\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实时显示摄像机反馈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，让我们像在遥控notebook中一样初始化并显示我们的相机。\n",
    "\n",
    "我们使用JetBot的Camera类来启用CSI MIPI摄像机。我们的神经网络将224x224像素的图像作为输入。我们将相机设置为该大小，以最大程度地减少数据集文件的大小（我们已经测试了它适用于此任务）。在某些情况下，以较大的图像大小收集数据会更好，然后再缩小为所需大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836dcaf9a645401185d8983cacb314d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e94715b93b4630947ff2e0c93674b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c84e144d7d45c59133a0f9d57a0c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='y', max=1.0, min=-1.0, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera = Camera.instance(width=224, height=224, fps=10)\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "target_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "x_slider = widgets.FloatSlider(min=-1.0, max=1.0, step=0.001, description='x')\n",
    "y_slider = widgets.FloatSlider(min=-1.0, max=1.0, step=0.001, description='y')\n",
    "\n",
    "def display_xy(camera_image):\n",
    "    image = np.copy(camera_image)\n",
    "    x = x_slider.value\n",
    "    y = y_slider.value\n",
    "    x = int(x * 224 / 2 + 112)\n",
    "    y = int(y * 224 / 2 + 112)\n",
    "    image = cv2.circle(image, (x, y), 8, (0, 255, 0), 3)\n",
    "    image = cv2.circle(image, (112, 224), 8, (0, 0,255), 3)\n",
    "    image = cv2.line(image, (x,y), (112,224), (255,0,0), 3)\n",
    "    jpeg_image = bgr8_to_jpeg(image)\n",
    "    return jpeg_image\n",
    "\n",
    "time.sleep(1)\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "traitlets.dlink((camera, 'value'), (target_widget, 'value'), transform=display_xy)\n",
    "\n",
    "display(widgets.HBox([image_widget, target_widget]), x_slider, y_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建游戏手柄控制器\n",
    "\n",
    "此步骤类似于“远程操作”任务。在此任务中，我们将使用游戏手柄控制器标记图像。\n",
    "\n",
    "我们要做的第一件事是创建Controller组件的实例，我们将使用它为图像标记“ x”和“ y”值。Controller组件带有一个索引参数，该参数指定控制器的编号。如果您连接了多个控制器，或者某些游戏手柄显示为多个控制器时很有用。要确定您正在使用的控制器的索引。\n",
    "\n",
    "访问http://html5gamepad.com.\n",
    "按下您正在使用的游戏板上的按钮。记住响应按钮按下的游戏板索引。下一步，我们将使用该索引创建并显示控制器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1590877f283c4deab090312a761627c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Controller()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controller = widgets.Controller(index=0)\n",
    "\n",
    "display(controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将Gamepad Controller和标记图像相关联\n",
    "\n",
    "现在，即使我们已经连接了游戏手柄，我们仍未将控制器关联到标记图像！我们将使用dlink函数将其连接到左右垂直轴。与link功能不同，dlink函数不允许我们在源和目标之间相互转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DirectionalLink(source=(Axis(value=0.0), 'value'), target=(FloatSlider(value=0.0, description='y', max=1.0, mi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.jsdlink((controller.axes[2], 'value'), (x_slider, 'value'))\n",
    "widgets.jsdlink((controller.axes[3], 'value'), (y_slider, 'value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 收集数据\n",
    "\n",
    "以下代码块将显示实时图像，以及我们已保存的图像数。我们将目标X，Y值通过以下方式存储\n",
    "\n",
    "1. 将绿点放在目标上\n",
    "2. 在手柄上按[4]保存\n",
    "这会将文件存储在文件夹``dataset_xy``中，文件名为\n",
    "``xy_<x value>_<y value>_<uuid>.jpg``\n",
    "\n",
    "训练时，我们加载图像并解析文件名中的x，y值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories not created becasue they already exist\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a5140f733640788fc83f71dde0fea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASET_DIR = 'dataset_xy'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(DATASET_DIR)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')\n",
    "\n",
    "for b in controller.buttons:\n",
    "    b.unobserve_all()\n",
    "\n",
    "count_widget = widgets.IntText(description='count', value=len(glob.glob(os.path.join(DATASET_DIR, '*.jpg'))))\n",
    "\n",
    "def xy_uuid(x, y):\n",
    "    return 'xy_%03d_%03d_%s' % (x * 50 + 50, y * 50 + 50, uuid1())\n",
    "\n",
    "def save_snapshot(change):\n",
    "    if change['new']:\n",
    "        uuid = xy_uuid(x_slider.value, y_slider.value)\n",
    "        image_path = os.path.join(DATASET_DIR, uuid + '.jpg')\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(image_widget.value)\n",
    "        count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "\n",
    "controller.buttons[4].observe(save_snapshot, names='value')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    target_widget,\n",
    "    count_widget\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下一步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "收集到足够的数据后，我们需要将该数据复制到我们的GPU台式机或云机上进行训练。首先，我们可以调用以下终端命令将数据集文件夹压缩为一个zip文件。\n",
    "\n",
    "> 如果您正在使用JetBot本身进行训练，则可以跳过此步骤！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "！前缀表示我们要将单元作为shell（或终端）命令运行。\n",
    "\n",
    "下面zip命令中的-r标志表示递归，以便我们包含所有嵌套文件，-q标志表示隐藏，以便zip命令不打印任何输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestr():\n",
    "    return str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "camera.stop()\n",
    "!zip -r -q road_following_{DATASET_DIR}_{timestr()}.zip {DATASET_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您应该在Jupyter Lab文件浏览器中看到一个名为road_following_ <Date＆Time> .zip的文件。您应该使用Jupyter Lab文件浏览器通过右键单击并选择下载来下载zip文件。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
